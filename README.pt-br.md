# DeepWiki-Open

![DeepWiki Banner](screenshots/Deepwiki.png)

**DeepWiki** √© minha pr√≥pria tentativa de implementa√ß√£o do DeepWiki, que cria automaticamente wikis bonitas e interativas para qualquer reposit√≥rio GitHub, GitLab ou BitBucket! Basta inserir o nome de um reposit√≥rio, e o DeepWiki ir√°:

1. Analisar a estrutura do c√≥digo
2. Gerar documenta√ß√£o abrangente
3. Criar diagramas visuais para explicar como tudo funciona
4. Organizar tudo em uma wiki f√°cil de navegar

[!["Buy Me A Coffee"](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://buymeacoffee.com/sheing)
[![Tip in Crypto](https://tip.md/badge.svg)](https://tip.md/sng-asyncfunc)
[![Twitter/X](https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://x.com/sashimikun_void)
[![Discord](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.com/invite/VQMBGR8u5v)

[English](./README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh.md) | [Êó•Êú¨Ë™û](./README.ja.md) | [Espa√±ol](./README.es.md) | [ÌïúÍµ≠Ïñ¥](./README.kr.md) | [Ti·∫øng Vi·ªát](./README.vi.md) | [Portugu√™s Brasileiro](./README.pt-br.md)

## ‚ú® Recursos

- **Documenta√ß√£o Instant√¢nea**: Transforme qualquer reposit√≥rio GitHub, GitLab ou BitBucket em uma wiki em segundos
- **Suporte a Reposit√≥rios Privados**: Acesse reposit√≥rios privados com seguran√ßa usando tokens de acesso pessoal
- **An√°lise Inteligente**: Compreens√£o da estrutura e relacionamentos do c√≥digo com IA
- **Diagramas Bonitos**: Diagramas Mermaid autom√°ticos para visualizar arquitetura e fluxo de dados
- **Navega√ß√£o F√°cil**: Interface simples e intuitiva para explorar a wiki
- **Recurso de Perguntas**: Converse com seu reposit√≥rio usando IA com RAG para obter respostas precisas
- **DeepResearch**: Processo de pesquisa em v√°rias etapas que investiga minuciosamente t√≥picos complexos
- **M√∫ltiplos Provedores de Modelos**: Suporte para Google Gemini, OpenAI, OpenRouter e modelos locais Ollama

## üöÄ In√≠cio R√°pido (Super F√°cil!)

### Op√ß√£o 1: Usando Docker

```bash
# Clone o reposit√≥rio
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Crie um arquivo .env com suas chaves de API
echo "GOOGLE_API_KEY=sua_chave_api_google" > .env
echo "OPENAI_API_KEY=sua_chave_api_openai" >> .env
# Opcional: Adicione a chave API OpenRouter se quiser usar modelos OpenRouter
echo "OPENROUTER_API_KEY=sua_chave_api_openrouter" >> .env
# Opcional: Adicione o host Ollama se n√£o for local. padr√£o: http://localhost:11434
echo "OLLAMA_HOST=seu_host_ollama" >> .env

# Execute com Docker Compose
docker-compose up
```

Para instru√ß√µes detalhadas sobre como usar o DeepWiki com Ollama e Docker, veja [Instru√ß√µes do Ollama (em ingl√™s)](Ollama-instruction.md).

> üí° **Onde obter essas chaves:**
> - Obtenha uma chave API Google no [Google AI Studio](https://makersuite.google.com/app/apikey)
> - Obtenha uma chave API OpenAI na [Plataforma OpenAI](https://platform.openai.com/api-keys)

### Op√ß√£o 2: Configura√ß√£o Manual (Recomendada)

#### Passo 1: Configure Suas Chaves API

Crie um arquivo `.env` na raiz do projeto com estas chaves:

```
GOOGLE_API_KEY=sua_chave_api_google
OPENAI_API_KEY=sua_chave_api_openai
# Opcional: Adicione isso se quiser usar modelos OpenRouter
OPENROUTER_API_KEY=sua_chave_api_openrouter
# Opcional: Adicione o host Ollama se n√£o for local. padr√£o: http://localhost:11434
OLLAMA_HOST=seu_host_ollama
```

#### Passo 2: Inicie o Backend

```bash
# Instale as depend√™ncias Python
pip install -r api/requirements.txt

# Inicie o servidor API
python -m api.main
```

#### Passo 3: Inicie o Frontend

```bash
# Instale as depend√™ncias JavaScript
npm install
# ou
yarn install

# Inicie o aplicativo web
npm run dev
# ou
yarn dev
```

#### Passo 4: Use o DeepWiki!

1. Abra [http://localhost:3000](http://localhost:3000) no seu navegador
2. Insira um reposit√≥rio GitHub, GitLab ou Bitbucket (como `https://github.com/openai/codex`, `https://github.com/microsoft/autogen`, `https://gitlab.com/gitlab-org/gitlab`, ou `https://bitbucket.org/redradish/atlassian_app_versions`)
3. Para reposit√≥rios privados, clique em "+ Adicionar tokens de acesso" e insira seu token de acesso pessoal do GitHub ou GitLab
4. Clique em "Gerar Wiki" e veja a m√°gica acontecer!

## üîç Como Funciona

O DeepWiki usa IA para:

1. Clonar e analisar o reposit√≥rio GitHub, GitLab ou Bitbucket (incluindo reposit√≥rios privados com autentica√ß√£o por token)
2. Criar embeddings do c√≥digo para recupera√ß√£o inteligente
3. Gerar documenta√ß√£o com IA contextual (usando modelos Google Gemini, OpenAI, OpenRouter ou Ollama local)
4. Criar diagramas visuais para explicar rela√ß√µes de c√≥digo
5. Organizar tudo em uma wiki estruturada
6. Permitir perguntas e respostas inteligentes com o reposit√≥rio atrav√©s do recurso de Perguntas
7. Fornecer capacidades de pesquisa aprofundada com DeepResearch

```mermaid
graph TD
    A[Usu√°rio insere repo GitHub/GitLab/Bitbucket] --> AA{Repo privado?}
    AA -->|Sim| AB[Adicionar token de acesso]
    AA -->|N√£o| B[Clonar Reposit√≥rio]
    AB --> B
    B --> C[Analisar Estrutura do C√≥digo]
    C --> D[Criar Embeddings do C√≥digo]

    D --> M{Selecionar Provedor de Modelo}
    M -->|Google Gemini| E1[Gerar com Gemini]
    M -->|OpenAI| E2[Gerar com OpenAI]
    M -->|OpenRouter| E3[Gerar com OpenRouter]
    M -->|Ollama Local| E4[Gerar com Ollama]

    E1 --> E[Gerar Documenta√ß√£o]
    E2 --> E
    E3 --> E
    E4 --> E

    D --> F[Criar Diagramas Visuais]
    E --> G[Organizar como Wiki]
    F --> G
    G --> H[DeepWiki Interativo]

    classDef process stroke-width:2px;
    classDef data stroke-width:2px;
    classDef result stroke-width:2px;
    classDef decision stroke-width:2px;

    class A,D data;
    class AA,M decision;
    class B,C,E,F,G,AB,E1,E2,E3,E4 process;
    class H result;
```

## üõ†Ô∏è Estrutura do Projeto

```
deepwiki/
‚îú‚îÄ‚îÄ api/                  # Servidor API backend
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Ponto de entrada da API
‚îÇ   ‚îú‚îÄ‚îÄ api.py            # Implementa√ß√£o FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ rag.py            # Retrieval Augmented Generation
‚îÇ   ‚îú‚îÄ‚îÄ data_pipeline.py  # Utilit√°rios de processamento de dados
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt  # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ src/                  # Aplicativo Next.js frontend
‚îÇ   ‚îú‚îÄ‚îÄ app/              # Diret√≥rio do aplicativo Next.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx      # P√°gina principal do aplicativo
‚îÇ   ‚îî‚îÄ‚îÄ components/       # Componentes React
‚îÇ       ‚îî‚îÄ‚îÄ Mermaid.tsx   # Renderizador de diagramas Mermaid
‚îÇ
‚îú‚îÄ‚îÄ public/               # Ativos est√°ticos
‚îú‚îÄ‚îÄ package.json          # Depend√™ncias JavaScript
‚îî‚îÄ‚îÄ .env                  # Vari√°veis de ambiente (crie este arquivo)
```

## ü§ñ Sistema de Sele√ß√£o de Modelos Baseado em Provedores

O DeepWiki agora implementa um sistema flex√≠vel de sele√ß√£o de modelos baseado em provedores, suportando m√∫ltiplos provedores de LLM:

### Provedores e Modelos Suportados

- **Google**: Padr√£o `gemini-2.0-flash`, tamb√©m suporta `gemini-1.5-flash`, `gemini-1.0-pro`, etc.
- **OpenAI**: Padr√£o `gpt-4o`, tamb√©m suporta `o4-mini`, etc.
- **OpenRouter**: Acesso a m√∫ltiplos modelos via uma API unificada, incluindo Claude, Llama, Mistral, etc.
- **Ollama**: Suporte para modelos de c√≥digo aberto executados localmente como `llama3`

### Vari√°veis de Ambiente

Cada provedor requer suas vari√°veis de ambiente de chave API correspondentes:

```
# Chaves API
GOOGLE_API_KEY=sua_chave_api_google        # Necess√°ria para modelos Google Gemini
OPENAI_API_KEY=sua_chave_api_openai        # Necess√°ria para modelos OpenAI
OPENROUTER_API_KEY=sua_chave_api_openrouter # Necess√°ria para modelos OpenRouter

# Configura√ß√£o de URL Base da API OpenAI
OPENAI_BASE_URL=https://endpoint-api-personalizado.com/v1  # Opcional, para endpoints de API OpenAI personalizados

# Host Ollama
OLLAMA_HOST=seu_host_ollama # Opcional, se Ollama n√£o for local. padr√£o: http://localhost:11434

# Diret√≥rio de Configura√ß√£o
DEEPWIKI_CONFIG_DIR=/caminho/para/dir/config/personalizado  # Opcional, para localiza√ß√£o personalizada de arquivos de configura√ß√£o
```

### Arquivos de Configura√ß√£o

O DeepWiki usa arquivos de configura√ß√£o JSON para gerenciar v√°rios aspectos do sistema:

1. **`generator.json`**: Configura√ß√£o para modelos de gera√ß√£o de texto
   - Define provedores de modelos dispon√≠veis (Google, OpenAI, OpenRouter, Ollama)
   - Especifica modelos padr√£o e dispon√≠veis para cada provedor
   - Cont√©m par√¢metros espec√≠ficos de modelo como temperatura e top_p

2. **`embedder.json`**: Configura√ß√£o para modelos de embedding e processamento de texto
   - Define modelos de embedding para armazenamento de vetores
   - Cont√©m configura√ß√£o do recuperador para RAG
   - Especifica configura√ß√µes do divisor de texto para divis√£o de documentos

3. **`repo.json`**: Configura√ß√£o para manipula√ß√£o de reposit√≥rios
   - Cont√©m filtros de arquivos para excluir certos arquivos e diret√≥rios
   - Define limites de tamanho de reposit√≥rio e regras de processamento

Por padr√£o, esses arquivos est√£o localizados no diret√≥rio `api/config/`. Voc√™ pode personalizar sua localiza√ß√£o usando a vari√°vel de ambiente `DEEPWIKI_CONFIG_DIR`.

### Sele√ß√£o de Modelo Personalizado para Provedores de Servi√ßo

O recurso de sele√ß√£o de modelo personalizado √© especificamente projetado para provedores de servi√ßo que precisam:

- Oferecer m√∫ltiplas op√ß√µes de modelo de IA para usu√°rios dentro de sua organiza√ß√£o
- Adaptar-se rapidamente ao panorama de LLM em r√°pida evolu√ß√£o sem mudan√ßas de c√≥digo
- Suportar modelos especializados ou ajustados que n√£o est√£o na lista predefinida

Provedores de servi√ßo podem implementar suas ofertas de modelo selecionando entre as op√ß√µes predefinidas ou inserindo identificadores de modelo personalizados na interface do frontend.

### Configura√ß√£o de URL Base para Canais Privados Empresariais

A configura√ß√£o base_url do Cliente OpenAI √© projetada principalmente para usu√°rios empresariais com canais de API privados. Este recurso:

- Permite conex√£o a endpoints de API privados ou espec√≠ficos da empresa
- Permite que organiza√ß√µes usem seus pr√≥prios servi√ßos LLM auto-hospedados ou implantados personalizados
- Suporta integra√ß√£o com servi√ßos compat√≠veis com a API OpenAI de terceiros

**Em Breve**: Em atualiza√ß√µes futuras, o DeepWiki suportar√° um modo onde os usu√°rios precisam fornecer suas pr√≥prias chaves API nas solicita√ß√µes. Isso permitir√° que clientes empresariais com canais privados usem seus arranjos de API existentes sem compartilhar credenciais com a implanta√ß√£o do DeepWiki.

## ü§© Usando Modelos de Embedding Compat√≠veis com OpenAI (ex., Alibaba Qwen)

Se voc√™ deseja usar modelos de embedding compat√≠veis com a API OpenAI (como Alibaba Qwen), siga estas etapas:

1. Substitua o conte√∫do de `api/config/embedder.json` pelo de `api/config/embedder_openai_compatible.json`.
2. No arquivo `.env` da raiz do seu projeto, defina as vari√°veis de ambiente relevantes, por exemplo:
   ```
   OPENAI_API_KEY=sua_chave_api
   OPENAI_API_BASE_URL=seu_endpoint_compativel_openai
   ```
3. O programa substituir√° automaticamente os espa√ßos reservados em embedder.json pelos valores de suas vari√°veis de ambiente.

Isso permite que voc√™ mude perfeitamente para qualquer servi√ßo de embedding compat√≠vel com OpenAI sem mudan√ßas de c√≥digo.

### Logging

O DeepWiki usa o m√≥dulo `logging` integrado do Python para sa√≠da de diagn√≥stico. Voc√™ pode configurar a verbosidade e o destino do arquivo de log via vari√°veis de ambiente:

| Vari√°vel        | Descri√ß√£o                                                        | Padr√£o                      |
|-----------------|--------------------------------------------------------------------|------------------------------|
| `LOG_LEVEL`     | N√≠vel de logging (DEBUG, INFO, WARNING, ERROR, CRITICAL).          | INFO                         |
| `LOG_FILE_PATH` | Caminho para o arquivo de log. Se definido, logs ser√£o escritos neste arquivo. | `api/logs/application.log`   |

Para habilitar logging de depura√ß√£o e direcionar logs para um arquivo personalizado:
```bash
export LOG_LEVEL=DEBUG
export LOG_FILE_PATH=./debug.log
python -m api.main
```
Ou com Docker Compose:
```bash
LOG_LEVEL=DEBUG LOG_FILE_PATH=./debug.log docker-compose up
```

Ao executar com Docker Compose, o diret√≥rio `api/logs` do container √© montado em `./api/logs` no seu host (veja a se√ß√£o `volumes` em `docker-compose.yml`), garantindo que os arquivos de log persistam entre reinicializa√ß√µes.

Alternativamente, voc√™ pode armazenar essas configura√ß√µes no seu arquivo `.env`:

```bash
LOG_LEVEL=DEBUG
LOG_FILE_PATH=./debug.log
```
Ent√£o simplesmente execute:

```bash
docker-compose up
```

**Considera√ß√µes de Seguran√ßa do Caminho de Logging:** Em ambientes de produ√ß√£o, garanta que o diret√≥rio `api/logs` e qualquer caminho de arquivo de log personalizado estejam protegidos com permiss√µes de sistema de arquivos e controles de acesso apropriados. O aplicativo imp√µe que `LOG_FILE_PATH` resida dentro do diret√≥rio `api/logs` do projeto para evitar travessia de caminho ou escritas n√£o autorizadas.

## üîß Configura√ß√£o Avan√ßada

### Vari√°veis de Ambiente

| Vari√°vel             | Descri√ß√£o                                                  | Obrigat√≥ria | Observa√ß√£o                                                                                                     |
|----------------------|--------------------------------------------------------------|----------|----------------------------------------------------------------------------------------------------------|
| `GOOGLE_API_KEY`     | Chave API Google Gemini para gera√ß√£o com IA                      | N√£o | Necess√°ria apenas se voc√™ quiser usar modelos Google Gemini                                                    
| `OPENAI_API_KEY`     | Chave API OpenAI para embeddings                                | Sim | Nota: Isso √© necess√°rio mesmo se voc√™ n√£o estiver usando modelos OpenAI, pois √© usado para embeddings.              |
| `OPENROUTER_API_KEY` | Chave API OpenRouter para modelos alternativos                    | N√£o | Necess√°ria apenas se voc√™ quiser usar modelos OpenRouter                                                       |
| `OLLAMA_HOST`        | Host Ollama (padr√£o: http://localhost:11434)                | N√£o | Necess√°ria apenas se voc√™ quiser usar servidor Ollama externo                                                  |
| `PORT`               | Porta para o servidor API (padr√£o: 8001)                      | N√£o | Se voc√™ hospedar API e frontend na mesma m√°quina, certifique-se de alterar a porta de `SERVER_BASE_URL` de acordo |
| `SERVER_BASE_URL`    | URL base para o servidor API (padr√£o: http://localhost:8001) | N√£o |
| `DEEPWIKI_AUTH_MODE` | Defina como `true` ou `1` para habilitar o modo de autoriza√ß√£o. | N√£o | Padr√£o √© `false`. Se habilitado, `DEEPWIKI_AUTH_CODE` √© necess√°rio. |
| `DEEPWIKI_AUTH_CODE` | O c√≥digo secreto necess√°rio para gera√ß√£o de wiki quando `DEEPWIKI_AUTH_MODE` est√° habilitado. | N√£o | Usado apenas se `DEEPWIKI_AUTH_MODE` for `true` ou `1`. |

Se voc√™ n√£o estiver usando o modo ollama, voc√™ precisa configurar uma chave API OpenAI para embeddings. Outras chaves API s√£o necess√°rias apenas ao configurar e usar modelos dos provedores correspondentes.

## Modo de Autoriza√ß√£o

O DeepWiki pode ser configurado para executar em um modo de autoriza√ß√£o, onde a gera√ß√£o de wiki requer um c√≥digo de autoriza√ß√£o v√°lido. Isso √© √∫til se voc√™ quiser controlar quem pode usar o recurso de gera√ß√£o.
Restringe a inicia√ß√£o do frontend e protege a exclus√£o de cache, mas n√£o impede completamente a gera√ß√£o de backend se os endpoints da API forem acessados diretamente.

Para habilitar o modo de autoriza√ß√£o, defina as seguintes vari√°veis de ambiente:

- `DEEPWIKI_AUTH_MODE`: Defina como `true` ou `1`. Quando habilitado, o frontend exibir√° um campo de entrada para o c√≥digo de autoriza√ß√£o.
- `DEEPWIKI_AUTH_CODE`: Defina como o c√≥digo secreto desejado. Restringe a inicia√ß√£o do frontend e protege a exclus√£o de cache, mas n√£o impede completamente a gera√ß√£o de backend se os endpoints da API forem acessados diretamente.

Se `DEEPWIKI_AUTH_MODE` n√£o estiver definido ou estiver definido como `false` (ou qualquer outro valor diferente de `true`/`1`), o recurso de autoriza√ß√£o ser√° desativado, e nenhum c√≥digo ser√° necess√°rio.

### Configura√ß√£o Docker

Voc√™ pode usar Docker para executar o DeepWiki:

```bash
# Baixe a imagem do GitHub Container Registry
docker pull ghcr.io/asyncfuncai/deepwiki-open:latest

# Execute o container com vari√°veis de ambiente
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=sua_chave_api_google \
  -e OPENAI_API_KEY=sua_chave_api_openai \
  -e OPENROUTER_API_KEY=sua_chave_api_openrouter \
  -e OLLAMA_HOST=seu_host_ollama \
  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
```

Este comando tamb√©m monta `~/.adalflow` no seu host para `/root/.adalflow` no container. Este caminho √© usado para armazenar:
- Reposit√≥rios clonados (`~/.adalflow/repos/`)
- Seus embeddings e √≠ndices (`~/.adalflow/databases/`)
- Conte√∫do de wiki gerado em cache (`~/.adalflow/wikicache/`)

Isso garante que seus dados persistam mesmo se o container for parado ou removido.

Ou use o arquivo `docker-compose.yml` fornecido:

```bash
# Edite o arquivo .env com suas chaves API primeiro
docker-compose up
```

(O arquivo `docker-compose.yml` √© pr√©-configurado para montar `~/.adalflow` para persist√™ncia de dados, similar ao comando `docker run` acima.)

#### Usando um arquivo .env com Docker

Voc√™ tamb√©m pode montar um arquivo .env no container:

```bash
# Crie um arquivo .env com suas chaves API
echo "GOOGLE_API_KEY=sua_chave_api_google" > .env
echo "OPENAI_API_KEY=sua_chave_api_openai" >> .env
echo "OPENROUTER_API_KEY=sua_chave_api_openrouter" >> .env
echo "OLLAMA_HOST=seu_host_ollama" >> .env

# Execute o container com o arquivo .env montado
docker run -p 8001:8001 -p 3000:3000 \
  -v $(pwd)/.env:/app/.env \
  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
```

Este comando tamb√©m monta `~/.adalflow` no seu host para `/root/.adalflow` no container. Este caminho √© usado para armazenar:
- Reposit√≥rios clonados (`~/.adalflow/repos/`)
- Seus embeddings e √≠ndices (`~/.adalflow/databases/`)
- Conte√∫do de wiki gerado em cache (`~/.adalflow/wikicache/`)

Isso garante que seus dados persistam mesmo se o container for parado ou removido.
#### Construindo a imagem Docker localmente

Se voc√™ quiser construir a imagem Docker localmente:

```bash
# Clone o reposit√≥rio
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Construa a imagem Docker
docker build -t deepwiki-open .

# Execute o container
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=sua_chave_api_google \
  -e OPENAI_API_KEY=sua_chave_api_openai \
  -e OPENROUTER_API_KEY=sua_chave_api_openrouter \
  -e OLLAMA_HOST=seu_host_ollama \
  deepwiki-open
```

### Detalhes do Servidor API

O servidor API fornece:
- Clonagem e indexa√ß√£o de reposit√≥rios
- RAG (Retrieval Augmented Generation)
- Completions de chat com streaming

Para mais detalhes, veja o [README da API](./api/README.md).

## üîå Integra√ß√£o com OpenRouter

O DeepWiki agora suporta [OpenRouter](https://openrouter.ai/) como provedor de modelos, dando acesso a centenas de modelos de IA atrav√©s de uma √∫nica API:

- **M√∫ltiplas Op√ß√µes de Modelos**: Acesse modelos da OpenAI, Anthropic, Google, Meta, Mistral e mais
- **Configura√ß√£o Simples**: Apenas adicione sua chave API OpenRouter e selecione o modelo que deseja usar
- **Efici√™ncia de Custo**: Escolha modelos que se adequem ao seu or√ßamento e necessidades de desempenho
- **Troca F√°cil**: Alterne entre diferentes modelos sem alterar seu c√≥digo

### Como Usar o OpenRouter com DeepWiki

1. **Obtenha uma Chave API**: Cadastre-se no [OpenRouter](https://openrouter.ai/) e obtenha sua chave API
2. **Adicione ao Ambiente**: Adicione `OPENROUTER_API_KEY=sua_chave` ao seu arquivo `.env`
3. **Habilite na UI**: Marque a op√ß√£o "Usar API OpenRouter" na p√°gina inicial
4. **Selecione o Modelo**: Escolha entre modelos populares como GPT-4o, Claude 3.5 Sonnet, Gemini 2.0 e mais

O OpenRouter √© particularmente √∫til se voc√™ quiser:
- Experimentar diferentes modelos sem se cadastrar em m√∫ltiplos servi√ßos
- Acessar modelos que podem estar restritos em sua regi√£o
- Comparar desempenho entre diferentes provedores de modelos
- Otimizar custo vs. desempenho com base em suas necessidades

## ü§ñ Recursos de Perguntas & DeepResearch

### Recurso de Perguntas

O recurso de Perguntas permite que voc√™ converse com seu reposit√≥rio usando Retrieval Augmented Generation (RAG):

- **Respostas Contextuais**: Obtenha respostas precisas baseadas no c√≥digo real em seu reposit√≥rio
- **Alimentado por RAG**: O sistema recupera trechos de c√≥digo relevantes para fornecer respostas fundamentadas
- **Streaming em Tempo Real**: Veja as respostas conforme s√£o geradas para uma experi√™ncia mais interativa
- **Hist√≥rico de Conversa√ß√£o**: O sistema mant√©m contexto entre perguntas para intera√ß√µes mais coerentes

### Recurso DeepResearch

O DeepResearch leva a an√°lise de reposit√≥rios a um novo n√≠vel com um processo de pesquisa em v√°rias etapas:

- **Investiga√ß√£o Aprofundada**: Explora minuciosamente t√≥picos complexos atrav√©s de m√∫ltiplas itera√ß√µes de pesquisa
- **Processo Estruturado**: Segue um plano de pesquisa claro com atualiza√ß√µes e uma conclus√£o abrangente
- **Continua√ß√£o Autom√°tica**: A IA continua automaticamente a pesquisa at√© chegar a uma conclus√£o (at√© 5 itera√ß√µes)
- **Est√°gios de Pesquisa**:
  1. **Plano de Pesquisa**: Descreve a abordagem e descobertas iniciais
  2. **Atualiza√ß√µes de Pesquisa**: Constru√≠do sobre itera√ß√µes anteriores com novos insights
  3. **Conclus√£o Final**: Fornece uma resposta abrangente baseada em todas as itera√ß√µes

Para usar o DeepResearch, simplesmente alterne o interruptor "Pesquisa Aprofundada" na interface de Perguntas antes de enviar sua pergunta.

## üì± Capturas de Tela

![Interface Principal do DeepWiki](screenshots/Interface.png)
*A interface principal do DeepWiki*

![Suporte a Reposit√≥rios Privados](screenshots/privaterepo.png)
*Acesse reposit√≥rios privados com tokens de acesso pessoal*

![Recurso DeepResearch](screenshots/DeepResearch.png)
*DeepResearch conduz investiga√ß√µes em v√°rias etapas para t√≥picos complexos*

### V√≠deo de Demonstra√ß√£o

[![V√≠deo de Demonstra√ß√£o do DeepWiki](https://img.youtube.com/vi/zGANs8US8B4/0.jpg)](https://youtu.be/zGANs8US8B4)

*Veja o DeepWiki em a√ß√£o!*

## ‚ùì Solu√ß√£o de Problemas

### Problemas com Chaves API
- **"Vari√°veis de ambiente ausentes"**: Certifique-se de que seu arquivo `.env` est√° na raiz do projeto e cont√©m as chaves API necess√°rias
- **"Chave API n√£o v√°lida"**: Verifique se voc√™ copiou a chave completa corretamente sem espa√ßos extras
- **"Erro de API OpenRouter"**: Verifique se sua chave API OpenRouter √© v√°lida e tem cr√©ditos suficientes

### Problemas de Conex√£o
- **"N√£o √© poss√≠vel conectar ao servidor API"**: Certifique-se de que o servidor API est√° em execu√ß√£o na porta 8001
- **"Erro CORS"**: A API est√° configurada para permitir todas as origens, mas se voc√™ estiver tendo problemas, tente executar frontend e backend na mesma m√°quina

### Problemas de Gera√ß√£o
- **"Erro ao gerar wiki"**: Para reposit√≥rios muito grandes, tente um menor primeiro
- **"Formato de reposit√≥rio inv√°lido"**: Certifique-se de que est√° usando um formato de URL GitHub, GitLab ou Bitbucket v√°lido
- **"N√£o foi poss√≠vel buscar a estrutura do reposit√≥rio"**: Para reposit√≥rios privados, certifique-se de ter inserido um token de acesso pessoal v√°lido com as permiss√µes apropriadas
- **"Erro de renderiza√ß√£o de diagrama"**: O aplicativo tentar√° corrigir automaticamente diagramas quebrados

### Solu√ß√µes Comuns
1. **Reinicie ambos os servidores**: √Äs vezes um simples reinicio resolve a maioria dos problemas
2. **Verifique os logs do console**: Abra as ferramentas de desenvolvedor do navegador para ver quaisquer erros JavaScript
3. **Verifique os logs da API**: Olhe o terminal onde a API est√° em execu√ß√£o para erros Python

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para:
- Abrir issues para bugs ou solicita√ß√µes de recursos
- Enviar pull requests para melhorar o c√≥digo
- Compartilhar seu feedback e ideias

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ‚≠ê Hist√≥rico de Estrelas

[![Gr√°fico de Hist√≥rico de Estrelas](https://api.star-history.com/svg?repos=AsyncFuncAI/deepwiki-open&type=Date)](https://star-history.com/#AsyncFuncAI/deepwiki-open&Date)
